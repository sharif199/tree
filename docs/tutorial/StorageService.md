 


## Storage Service

## Table of Contents <a name="TOC"></a>
- [Storage Service](#storage-service)
- [Table of Contents <a name="TOC"></a>](#table-of-contents)
- [Introduction <a name="Introduction"></a>](#introduction)
- [Record structure <a name="Record-structure"></a>](#record-structure)
- [Schema structure <a name="Schema"></a>](#schema-structure)
- [Ingestion workflow <a name="Ingestion-workflow"></a>](#ingestion-workflow)
  - [Becoming a Data Ecosystem user <a name="Becoming-a-Data-Ecosystem-user"></a>](#becoming-a-data-ecosystem-user)
  - [Choosing a partition <a name="Choosing-a-partition"></a>](#choosing-a-partition)
  - [Creating data groups <a name="Creating-data-groups"></a>](#creating-data-groups)
  - [Creating the schema <a name="Creating-the-schema"></a>](#creating-the-schema)
  - [Creating the legal tag <a name="Creating-the-legal-tag"></a>](#creating-the-legal-tag)
  - [Creating records <a name="Creating-records"></a>](#creating-records)
  - [Ingesting records <a name="Ingesting-records"></a>](#ingesting-records)
- [Storage service APIs <a name="Storage-APIs"></a>](#storage-service-apis)
- [Schemas <a name="schemas"></a>](#schemas)
  - [Create Schema <a name="Create-schema"></a>](#create-schema)
  - [Get Schema <a name="Get-schema"></a>](#get-schema)
- [Query <a name="query"></a>](#query)
  - [Query all kinds <a name="Query-kinds"></a>](#query-all-kinds)
    - [Parameters <a name="parameters"></a>](#parameters)
  - [Fetch Records <a name="Fetch-records"></a>](#fetch-records)
- [Records <a name="record"></a>](#records)
  - [Create or Update records <a name="Creating-records"></a>](#create-or-update-records)
  - [Get record version <a name="Retrieve-specific-version"></a>](#get-record-version)
    - [Parameters <a name="parameters"></a>](#parameters-1)
  - [Get all record versions <a name="Retrieve-all-record-versions"></a>](#get-all-record-versions)
  - [Get record <a name="Retrieve-latest-record-version"></a>](#get-record)
    - [Parameters <a name="parameters"></a>](#parameters-2)
  - [Delete record <a name="Delete-record"></a>](#delete-record)
  - [Delete records <a name="Delete-records"></a>](#delete-records)
- [Patch api <a name="patch-api"></a>](#patch-api)
  - [Replace Tags, ACLs and Legal Tags <a name="patch-api-metadata-bulk-replace"></a>](#patch-api-metadata-bulk-replace)
  - [Add Tags, ACLs and Legal Tags <a name="patch-api-metadata-bulk-add"></a>](#patch-api-metadata-bulk-add)
  - [Remove Tags, ACLs and Legal Tags <a name="patch-api-metadata-bulk-remove"></a>](#patch-api-metadata-bulk-remove)
- [Using service accounts to access Storage APIs <a name="Service-accounts"></a>](#using-service-accounts-to-access-storage-apis)
- [Using skipdupes <a name="skipdupes"></a>](#using-skipdupes)
- [Support for GeoJSON types <a name="geojson-support"></a>](#support-for-geojson-types)
- [Version info endpoint](#version-info-endpoint)

## Introduction <a name="Introduction"></a>
After performing the basic user management procedures (create users and groups, assign users to groups, etc.) through [Entitlements Service](/solutions/dataecosystem/tutorials/entitlementsservice), DELFI developer can use the Data Ecosystem Storage Service to ingest metadata information generated by DELFI applications into the Data Ecosystem. The Storage Service provides a set of APIs to manage the entire metadata life-cycle such as ingestion (persistence), modification, deletion, versioning and data schema.

[Back to table of contents](#TOC)

## Record structure <a name="Record-structure"></a>
From the Storage Service perspective, the metadata to be ingested is called __record__. Below is a basic example of a Data Ecosystem record with a brief explanation of each field:

```
{
   "id": "common:hello:123456",
   "kind": "common:test:hello:1.0.0",
   "acl": {
     "viewers": ["data.default.viewers@common.[osdu.opengroup.org]"],
     "owners": ["data.default.owners@common.[osdu.opengroup.org]"]
   },
   "legal": {
     "legaltags": ["common-sample-legaltag"],
     "otherRelevantDataCountries": ["FR","US","CA"]
   },
   "data": {
     "msg": "Hello World, Data Ecosystem!"
   }
}
```

* __id__: _(optional)_ Unique identifier in the Data Ecosystem. When not provided, the service will create and assign an id to the record. Must follow the naming convention: ``{Data-Partition-Id}:{object-type}:{uuid}``.
* __kind__: _(mandatory)_ Kind of data being ingested. Must follow the naming convention: ``{Data-Partition-Id}:{dataset-name}:{record-type}:{version}``.
* __acl__: _(mandatory)_ Group of users who have access to the record. 
    * __acl.viewers__: List of valid groups which will have view/read privileges over the record. We follow the naming convention such that data groups begin with ``data.``.
    * __acl.owners__: List of valid groups which will have write privileges over the record. We follow the naming convention such that data groups begin with ``data.``.
* __legal__: _(mandatory)_ Attributes which represent the legal constraints associated with the record.
    * __legal.legaltags__: List of legal tag names associated with the record.
    * __legal.otherRelevantDataCountries__: List of other relevant data countries. Must have at least 2 values: where the data was ingested from and where Data Ecosystem stores the data.
* __data__: _(mandatory)_ Record payload represented as a list of key-value pairs.

[Back to table of contents](#TOC)


## Schema structure <a name="Schema"></a>
Another important concept in the Data Ecosystem Storage Service is __schema__. Schema is a structure, also defined in JSON, which provides data type information for the record fields. In other words, the schema defines whether a given field in the record is a ``string``, or an ``integer``, or a ``float``, or a ``geopoint``, etc.

> It is important to note that __only__ fields with schema information associated with are indexed by the [Search Service](/solutions/dataecosystem/tutorials/searchservice). For this reason, the DELFI developer __must__ create the respective schema for his/her records kind __before__ start ingesting records into the Data Ecosystem.

Schemas and records are tied together by the __kind__ attribute. On top of that, a given __kind__ can have zero or exactly one schema associated with. Having that concept in mind, the DELFI developer can make use of two APIs for schema management provided by the Data Ecosystem Storage Service:

```
POST /api/storage/v2/schemas
GET /api/storage/v2/schemas/{kind}
```

[Back to table of contents](#TOC)


## Ingestion workflow <a name="Ingestion-workflow"></a>

For sake of demonstration of the schema and records concepts as well as their respective APIs, lets consider the following use case:

> The DELFI developer wants to ingest metadata information related to his/her well dataset. The metadata contains the following pieces of information: name of the well, company name, year when it was drilled, total depth, and the well location.

In summary, to execute the above workflow, the DELFI developer needs to perform the following tasks:

1. Be a valid Data Ecosystem user;
2. Define which partition to use;
3. Create and/or assign users to a existing partition data group;
4. Agree on the __kind__ attribute which will represent the developer's wells. Let's assume it to be ``common:welldb:wellbore:1.0.0``;
5. Create the __legal tag__ that represents the legal constraints for the metadata to be ingested;
6. Create a schema for the kind ``common:welldb:wellbore:1.0.0`` via the ``POST /api/storage/v2/schemas`` API;
7. Create and ingest records via the ``PUT /api/storage/v2/records`` API.


### Becoming a Data Ecosystem user <a name="Becoming-a-Data-Ecosystem-user"></a>
Please refer to [Entitlements Service](/solutions/dataecosystem/tutorials/entitlementsservice) to learn how to become a valid Data Ecosystem user.


### Choosing a partition <a name="Choosing-a-partition"></a>
The Data Ecosystem stores data in different tenants depending on the different accounts in the  system. A user may belong to many accounts in DELFI e.g. a OSDU user may belong to both the OSDU account and a customer's account. When a user logs into the DELFI portal, one chooses which account to be active.
When using the Storage Service APIs, specify the active account as the ``Data-Partition-Id``. The correct values can be obtained from CFS services. In our Development environment you can choose between ``osdu``, ``customer`` and ``common``;


### Creating data groups <a name="Creating-data-groups"></a>
Please refer to [Entitlements Service](/solutions/dataecosystem/tutorials/entitlementsservice) to learn how to create data groups (the ones which starts with ``data.``) and assign users to them. For data access authorization purposes in this example, let's assume the groups ``data.default.viewers@common.[osdu.opengroup.org]`` and ``data.default.owners@common.[osdu.opengroup.org]`` were previously created via [Entitlements Service](/solutions/dataecosystem/tutorials/entitlementsservice).


### Creating the schema <a name="Creating-the-schema"></a>
The schema creation is done via the ``POST /api/storage/v2/schemas`` API. For the sample workflow in question, the schema could be created as follows:

<details><summary>curl</summary>

```
curl --request POST \
  --url '/api/storage/v2/schemas' \
  --header 'accept: application/json' \
  --header 'authorization: Bearer <JWT>' \
  --header 'content-type: application/json' \
  --header 'Data-Partition-Id: common' \
  --data '{
      "kind": "common:welldb:wellbore:1.0.0",
      "schema": [
        {
          "path": "name",
          "kind": "string"
        },
        {
          "path": "company",
          "kind": "string"
        },
        {
          "path": "drillingYear",
          "kind": "int"
        },
        {
          "path": "depth",
          "kind": "float"
        },
        {
          "path": "location",
          "kind": "core:dl:geopoint:1.0.0"
        }
      ]
}'
```
</details>

The schema is basically composed by a list of path/kinds pairs where the record fields are related to their data type. For more information about the supported schema data types, please refer to the [Schema API documentation](/solutions/dataecosystem/apis/p4d-data-ecosystem-storage-service).

### Creating the legal tag <a name="Creating-the-legal-tag"></a>
Please refer to [Compliance Service](/solutions/dataecosystem/tutorials/complianceservice) for legal tag creation. For this example, let's assume a legal tag called ``delfi-well-legal`` is created already.


### Creating records <a name="Creating-records"></a>
After the legal tag creation and schema definition, the records of the kind ``common:welldb:wellbore:1.0.0`` can be created. They need to follow the same structure and fields' naming convention as defined in the schema. A sample record would be something as follows:

<details><summary>curl</summary>

```
{
  "kind": "common:welldb:wellbore:1.0.0",
  "acl": {
    "viewers": ['data.default.viewers@common.[osdu.opengroup.org]'],
    "owners": ['data.default.owners@common.[osdu.opengroup.org]']
  },
  "legal": {
    "legaltags": ['common-sample-legaltag'],
    "otherRelevantDataCountries": ["FR","US","CA"]
  },
  "data": {
    "name": "well1",
    "company": "slb",
    "drillingYear": 1983,
    "depth": 1208.84,
    "location": {
      "latitude": 29.7512026,
      "longitude": -95.4812934
    }
  }
}
```
</details>


### Ingesting records <a name="Ingesting-records"></a>
Having the record structure defined, the DELFI developer must use the ``PUT /api/storage/v2/records'`` API to ingest his/her records, as follows:

<details><summary>curl</summary>

```
curl --request PUT \
  --url '/api/storage/v2/records' \
  --header 'accept: application/json' \
  --header 'authorization: Bearer <JWT>' \
  --header 'content-type: application/json' \
  --header 'Data-Partition-Id: common' \
  --data '[
  {
    "kind": "common:welldb:wellbore:1.0.0",
    "acl": {
      "viewers": ['data.default.viewers@common.[osdu.opengroup.org]'],
      "owners": ['data.default.owners@common.[osdu.opengroup.org]']
    },
    "legal": {
      "legaltags": ['common-sample-legaltag'],
      "otherRelevantDataCountries": ["FR","US","CA"]
    },
    "data": {
      "name": "well1",
      "company": "slb",
      "drillingYear": 1983,
      "depth": 1208.84,
      "location": {
        "latitude": 29.7512026,
        "longitude": -95.4812934
      }
    },
  {
    "kind": "common:welldb:wellbore:1.0.0",
    "acl": {
      "viewers": ['data.default.viewers@common.[osdu.opengroup.org]'],
      "owners": ['data.default.owners@common.[osdu.opengroup.org]']
    },
    "legal": {
      "legaltags": ['common-sample-legaltag'],
      "otherRelevantDataCountries": ["IN","BR","CA"]
    },
    "data": {
      "name": "well12312",
      "company": "shell",
      "drillingYear": 2001,
      "depth": 208.84,
      "location": {
        "latitude": 49.7512026,
        "longitude": -65.4812934
      }
    }
  },
   ...]'
```
</details>

[Back to table of contents](#TOC)

## Storage service APIs <a name="Storage-APIs"></a>
The Data Ecosystem Storage service has three different categories of API's 1.Schemas 2.Records 3.Query for schema and record management.

## Schemas <a name="schemas"></a>
### Create Schema <a name="Create-schema"></a>
Schema creation is explained at [Creating the schema](#Creating-the-schema) section.

### Get Schema <a name="Get-schema"></a>
The schema for a given 'kind' can be retrieved using the Get Schema API.
```
GET /api/storage/v2/schemas/{kind}
```

<details><summary>curl</summary>

``` 

curl --request GET \
   --url '/api/storage/v2/schemas/{kind}' \
   --header 'accept: application/json' \
   --header 'authorization: Bearer <JWT>' \
   --header 'content-type: application/json' \
   --header 'Data-Partition-Id: common' 
``` 
</details>

## Query <a name="query"></a>

### Query all kinds <a name="Query-kinds"></a>
The API returns a list of all kinds in the specific {Data-Partition-Id}. 
```
 GET /api/storage/v2/query/kinds
```

#### Parameters <a name="parameters"></a>

| Parameter | Description |
| :--- | :--- |
| limit | The maximum number of results to return from the given offset. If no limit is provided, then it will return __10__ items. Max number of items which can be fetched by the query is __100__.|

<details><summary>curl</summary>

```
curl --request GET \
  --url '/api/storage/v2/query/kinds' \
  --header 'accept: application/json' \
  --header 'authorization: Bearer <JWT>' \
  --header 'content-type: application/json' \
  --header 'Data-Partition-Id: common' 
  --data '{
  "limit": 10,
 }
```
</details>

### Fetch Records <a name="Fetch-records"></a>
The API fetches multiple records(maximum 20) from storage service at once, it allows user to request data being converted to common standard by using customized header {frame-of-reference}. Common standard is units in SI, crs in wgs84, elevation in msl, azimuth in true north, dates in utc.
Currently only "none" and "units=SI;crs=wgs84;elevation=msl;azimuth=true north;dates=utc;" are valid values for the header {frame-of-reference}. 


As of now, we only support conversion for units and crs. For Unit conversion, we only support conversions of arrays of values and properties of arrays of objects when the array element is the root object. For example, below Object/Array types are supported for unit conversion:
`VerticalMeasurement[].Measurements.VerticalMeasurement,
VerticalMeasurements[].VerticalMeasurement,
VerticalMeasurements.VerticalMeasurement`

However, below is not supported
`VerticalMeasurement.Measurements[].VerticalMeasurement`
`VerticalMeasurements[].Measurements[].VerticalMeasurement` (array element can not be nested inside) 

For Datetime conversion, Object and Array types are not supported yet. Elevation and Azimuth will be available later. Returned records could be either original value or converted(units=SI;crs=wgs84) value depending on users' requests and conversion status, original value will be returned when users not request the conversion or the conversion is requested but failed. In addition to records user requests, if conversion is requested, a list of conversion status of each record would be included in the response, indicating whether the conversion was successful or not, it not, what were the errors happened


```
POST /api/storage/v2/query/records:batch
```

<details><summary>curl</summary>

```
curl --request POST \
  --url '/api/storage/v2/query/records:batch' \
  --header 'Authorization: Bearer <JWT>' \
  --header 'Content-Type: application/json' \
  --header 'Data-Partition-Id: common' \
  --header 'frame-of-reference: units=SI;crs=wgs84;elevation=msl;azimuth=true north;dates=utc;' \
  --data '{
    "records": [
        "common:well:123456789",
        "common:wellTop:abc789456",
        "common:wellLog:4531wega22"
    ]
}
```
</details>

[Back to table of contents](#TOC)

## Records <a name="record"></a>
### Create or Update records <a name="Creating-records"></a>
The API represents the main injection mechanism into the Data Ecosystem. It allows records creation and/or update. When no record id is provided or when the provided id is not already present in the Data Ecosystemthen a new record is created. If the id is related to an existing record in the Data Ecosystemthen an update operation takes place and a new version of the record is created. 
More details available at [Creating records](#Creating-records) and [Ingesting records](#Ingesting-records) sections.

### Get record version <a name="Retrieve-specific-version"></a>
The API retrieves the specific version of the given record. 
```
GET /api/storage/v2/records/{id}/{version}

```
#### Parameters <a name="parameters"></a>

| Parameter | Description |
| :--- | :--- |
| attribute | Filter attributes to restrict the returned fields of the record. Usage: data.{record-data-field-name}.|

<details><summary>curl</summary>

```

 curl --request GET \
  --url '/api/storage/v2/records/{id}/{version}' \
  --header 'accept: application/json' \
  --header 'authorization: Bearer <JWT>' \
  --header 'content-type: application/json' \
  --header 'Data-Partition-Id: common' 
  --data '{
    "attributes": [
    "data.msg"
  ]
}
```
</details>

### Get all record versions <a name="Retrieve-all-record-versions"></a>
The API returns a list containing all versions for the given record id. 
```
GET /api/storage/v2/records/versions/{id}

```

<details><summary>curl</summary>

```
curl --request GET \
  --url '/api/storage/v2/records/versions/{id}'\
  --header 'accept: application/json' \
  --header 'authorization: Bearer <JWT>' \
  --header 'content-type: application/json' \
  --header 'Data-Partition-Id: common' 
```
</details>


### Get record <a name="Retrieve-latest-record-version"></a>
This API returns the latest version of the given record.
```
GET /api/storage/v2/records/{id}
```

#### Parameters <a name="parameters"></a>

| Parameter | Description |
| :--- | :--- |
| attribute | Filter attributes to restrict the returned fields of the record. Usage: data.{record-data-field-name}.|

<details><summary>curl</summary>

```
curl --request GET \
  --url '/api/storage/v2/records/{id}'\
  --header 'accept: application/json' \
  --header 'authorization: Bearer <JWT>' \
  --header 'content-type: application/json' \
  --header 'Data-Partition-Id: common' \
  --data '{
    "attributes": [
    "data.msg"
  ]
}

```
</details>


### Delete record <a name="Delete-record"></a>
The API performs a logical deletion of the given record. This operation can be reverted later.
```
POST /api/storage/v2/records/{id}:delete
```

<details><summary>curl</summary>

```
curl --request POST \
   --url '/api/storage/v2/records/{id}:delete' \
   --header 'accept: application/json' \
   --header 'authorization: Bearer <JWT>' \
   --header 'content-type: application/json'\
   --header 'Data-Partition-Id: common'
```
</details>

### Delete records <a name="Delete-records"></a>
The API performs a logical deletion of batch of record (max size of a batch is 500 records). This operation can be reverted later by ingesting record with the same id one more time. The deleted (inactive) records will be removed from the index, and therefore will not be returned to the search result.
```
POST /api/storage/v2/records/delete
```

<details><summary>curl</summary>

```
curl --request POST \
   --url '/api/storage/v2/records/delete' \
   --header 'accept: application/json' \
   --header 'authorization: Bearer <JWT>' \
   --header 'content-type: application/json'\
   --header 'Data-Partition-Id: common'
   --data-raw '[
          "tenant:type:unique-identifier",
          "tenant:type:unique-identifier",
          "tenant:type:unique-identifier"
     ]'     
```
</details>

## Patch api <a name="patch-api"></a>

Bulk Update API allows the update of records metadata in batch. It takes an array of record ids with/without version
numbers with a maximum number of 500, and updates properties specified in the operation path with value and operation type
provided. If a version number is provided, updates will be applied to the specific version of the record. If not, the
latest version of the record will be updated. Users need to specify the corresponding data partition id in the header as
well.

Users need to provide op(operation type), path, and value in the field 'ops'. The currently supported operations are "
replace", "add", and "remove". The user should be part of the groups that are being replaced/added/removed as ACL. Users
specify the property they want to update in the "path" field, and new values should be provided in the "value" field.

Bulk Update API has the following response codes:


| Code | Description |
| :--- | :--- |
| 200 | The update operation succeeds fully, all records’ metadata get updated.|
| 206 | The update operation succeeds partially. Some records are not updated due to different reasons, including records not found or does not have permission to edit the records. For records whose version number was also provided in the request, they may be locked during metadata update, due to optimistic lock. In this case, the version users provided is not the latest one, the record may be updated by others. If the record version is locked, 'lockedRecordIds' field will be returned. They can retry later with the records’ latest version number, once the record is no longer locked.|
| 400 | The update operation fails when the remove operation makes Legal Tags or ACLs empty.|


```
PATCH /api/storage/v2/records
```

### Replace Tags, ACLs and Legal Tags <a name="patch-api-metadata-bulk-replace"></a>

In the "replace" operation, property value in "path" would be fully replaced by values provided in the "value" field. If
we need to replace tags ops.value should be colon separated string value.
<details><summary>curl</summary>

```
curl --request PATCH \
   --url '/api/storage/v2/records' \
   --header 'accept: application/json' \
   --header 'authorization: Bearer <JWT>' \
   --header 'content-type: application/json'\
   --header 'Data-Partition-Id: common'
    --data-raw ‘{ 
      "query": { 
        "ids": [
          "tenant1:type:unique-identifier:version",
          "tenant2:type:unique-identifier:version",
          "tenant3:type:unique-identifier:version"
        ]
      }, 
      "ops": [ { 
        "op": "replace", 
        "path": "/legal/legaltags", 
        "value": [
          "opendes-sample-legaltag1",
          "opendes-sample-legaltag2"
        ]
        }, 
        { 
	    "op": "replace", 
	    "path": "/acl/owners", 
	    "value": [
	      "data.default.owner1@opendes.enterprisedata.cloud.slb-ds.com",
	      "data.default.owner2@opendes.enterprisedata.cloud.slb-ds.com"
	    ]
        }, 
        { 
        "op": "replace", 
        "path": "/acl/viewers", 
        "value": [
          "data.default.viewer1@opendes.enterprisedata.cloud.slb-ds.com",
          "data.default.viewer2@opendes.enterprisedata.cloud.slb-ds.com"
        ] 
        },
        {
        "op":"replace",
        "path":"/tags",
        "value":[
          "key1:value1",
          "key2:value2",
          "key3:value3"
          ]
        }
      ] 
    }
```

</details>

### Add Tags, ACLs and Legal Tags <a name="patch-api-metadata-bulk-add"></a>

In the "add" operation, the valid Tags, Legal Tags, and ACLs (Acl Viewers, Acl Owners) provided in the "value" field
will be added to the property value in the "path" field. If we need to add tags ops.value should be colon separated
string value.


<details><summary>curl</summary>

```
curl --request PATCH \
   --url '/api/storage/v2/records' \
   --header 'accept: application/json' \
   --header 'authorization: Bearer <JWT>' \
   --header 'content-type: application/json'\
   --header 'Data-Partition-Id: common'
    --data-raw ‘{ 
      "query": { 
        "ids": [
          "tenant1:type:unique-identifier:version",
          "tenant2:type:unique-identifier:version",
          "tenant3:type:unique-identifier:version"
        ]
      }, 
      "ops": [ { 
        "op": "add", 
        "path": "/legal/legaltags", 
        "value": [
          "opendes-sample-legaltag1",
          "opendes-sample-legaltag2"
        ]
        }, 
        { 
	    "op": "add", 
	    "path": "/acl/owners", 
	    "value": [
	      "data.default.owner1@opendes.enterprisedata.cloud.slb-ds.com",
	      "data.default.owner2@opendes.enterprisedata.cloud.slb-ds.com"
	    ]
        }, 
        { 
        "op": "add", 
        "path": "/acl/viewers", 
        "value": [
          "data.default.viewer1@opendes.enterprisedata.cloud.slb-ds.com",
          "data.default.viewer2@opendes.enterprisedata.cloud.slb-ds.com"
        ]
        },
        {
        "op":"add",
        "path":"/tags",
        "value":[
          "key1:value1",
          "key2:value2",
          "key3:value3"
        ]
        }
      ]
    }
```

</details>

### Remove Tags, ACLs and Legal Tags <a name="patch-api-metadata-bulk-remove"></a>

In the "remove" operation, the valid Tags, Legal Tags, and ACLs (Acl Viewers, Acl Owners) provided in the "value" field
will be removed from the property value in the "path" field. When the given Tags, Legal Tags, or ACLs (Acl Viewers, Acl
Owners) do not exist in corresponding records, the remove succeeds without errors. The Legal Tags and ACLs (Acl Viewers,
Acl Owners) cannot be empty i.e. the user cannot remove all the Legal Tags or ACLs. If we need to remove tags ops.value
should be array of the tags keys which we are going to remove.


<details><summary>curl</summary>

```
curl --request PATCH \
   --url '/api/storage/v2/records' \
   --header 'accept: application/json' \
   --header 'authorization: Bearer <JWT>' \
   --header 'content-type: application/json'\
   --header 'Data-Partition-Id: common'
    --data-raw ‘{ 
      "query": { 
        "ids": [
          "tenant1:type:unique-identifier:version",
          "tenant2:type:unique-identifier:version",
          "tenant3:type:unique-identifier:version"
        ]
      }, 
      "ops": [ { 
        "op": "remove", 
        "path": "/legal/legaltags", 
        "value": [
          "opendes-sample-legaltag1",
          "opendes-sample-legaltag2"
        ]
        }, 
        { 
	    "op": "remove", 
	    "path": "/acl/owners", 
	    "value": [
	      "data.default.owner1@opendes.enterprisedata.cloud.slb-ds.com",
	      "data.default.owner2@opendes.enterprisedata.cloud.slb-ds.com"
	    ]
        }, 
        { 
        "op": "remove", 
        "path": "/acl/viewers", 
        "value": [
          "data.default.viewer1@opendes.enterprisedata.cloud.slb-ds.com",
          "data.default.viewer2@opendes.enterprisedata.cloud.slb-ds.com"
        ]
        },
        {
        "op":"remove",
        "path":"/tags",
        "value":[
          "key1",
          "key2",
          "key3"
        ]
        }
      ] 
    }
```

</details>

> You can use Search service's query or query_with_cursor [apis](https://community.opengroup.org/osdu/platform/system/search-service/-/blob/master/docs/tutorial/SearchService.md) to search for records based on tags. Since tags is part of metadata, it is automatically indexed. This may not work if the kind is old (older than when the tags feature was introduced ~02/25/2021). You may need to re-index the kind with the [reindex](https://community.opengroup.org/osdu/platform/system/indexer-service/-/blob/master/docs/tutorial/IndexerService.md#reindex) api (with `force_clean=true`) from indexer service.

## Using service accounts to access Storage APIs <a name="Service-accounts"></a>
The Storage service relies on the Google native data access authorization mechanisms to provide access control on the records. 
Based on design decisions, when the Storage service caller is a federated user, no additional configuration is necessary, however if the API caller is a service account, a mandatory configuration is necessary as follows:

- Navigate to the GCP project which the caller service account belongs to;
- Go to IAM & admin > service accounts;
- Select the caller service account;
- In the right-hand side Permissions panel, click at "Add member" button;
- In the member text box add the following email ``{DATA_ECOSYSTEM_PROJECT}@appspot.gserviceaccount.com``. For instance, in P4D enviroment the member email is ``p4d-ddl-eu-services@appspot.gserviceaccount.com``;
- Select the role ``Service Accounts`` > ``Service Account Token Creator``.

[Back to table of contents](#TOC)

## Using skipdupes <a name="skipdupes"></a> 
The skipdupes param is only related to update operations, which means you are calling the API with record IDs already present into the Data Ecosystem. If skipdupes==true, it means the service will not update the record if the payload is the same (duplicates). 
If there is a difference in the payload, then a new version of the record will be created. On the other hand, skipdupes == false, in an update operation, the service will not check whether the payload is the same or not and will always create a new version, even if identical to a previous version. On the response side, skipedRecordIds are the record IDs which weren't updated (skipped) due skipdupes == true and same payload. 
In PUT response, there will be no more replication in the record IDs, they will be in either recordIds or skippedRecordIds.

[Back to table of contents](#TOC)

## Support for GeoJSON types <a name="geojson-support"></a> 
Storage service can now ingest records of type [GeoJson](https://geojson.org/). Following are some examples of the `data` block which can be used to ingest records of type GeoJSON using the PUT api.
```
"data": {
  "WellName": "Data Platform Services - 51",
  "GeoShape": {
    "type": "Point",
    "coordinates": [
      -105.01621,
      39.57422
    ]
  }
}
```
```
"data": {
  "WellName": "Data Platform Services - 53",
  "GeoShape": {
    "type": "LineString",
    "coordinates": [
      [
        -101.744384,
        39.32155
      ],
      [
        -101.552124,
        39.330048
      ],
      [
        -101.403808,
        39.330048
      ]
    ]
  }
}
```
```
"data": {
  "WellName": "Data Platform Services - 55",
  "GeoShape": {
    "type": "Polygon",
    "coordinates": [
      [
        [
          100,
          0
        ],
        [
          101,
          0
        ],
        [
          101,
          1
        ],
        [
          100,
          1
        ],
        [
          100,
          0
        ]
      ]
    ]
  }
}
```
Similarly, data of type MultiPoint, MultiLineString, MultiPolygon, GeometryCollection are also supported.

[Back to table of contents](#TOC)

## Version info endpoint
For deployment available public `/info` endpoint, which provides build and git related information.
#### Example response:
```json
{
    "groupId": "org.opengroup.osdu",
    "artifactId": "storage-gcp",
    "version": "0.10.0-SNAPSHOT",
    "buildTime": "2021-07-09T14:29:51.584Z",
    "branch": "feature/GONRG-2681_Build_info",
    "commitId": "7777",
    "commitMessage": "Added copyright to version info properties file",
    "connectedOuterServices": [
      {
        "name": "elasticSearch",
        "version":"..."
      },
      {
        "name": "postgresSql",
        "version":"..."
      },
      {
        "name": "redis",
        "version":"..."
      }
    ]
}
```
This endpoint takes information from files, generated by `spring-boot-maven-plugin`,
`git-commit-id-plugin` plugins. Need to specify paths for generated files to matching
properties:
- `version.info.buildPropertiesPath`
- `version.info.gitPropertiesPath`

[Back to table of contents](#TOC)